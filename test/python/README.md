# Requirements

The key thing of the tests is that we want to run an "normal" workload. That is
to say, we want to run a linux kernel target initiator against it. For this we
use VMs. The fixture `target_vm()` is used in some of the tests and then uses
`async_cmd_run_at()` to execute remote work.

To set a target VM:

```
export TARGET_VM=$MY_VM
```

Setting up a VM, or what type of VM to use, is up to you. In the CI environment predefined VM's
will be available.

# Converting a .feature

A feature can automatically be converted to python code. This is not required but avoids mismatch between the two.

```
pytest-bdd generate xxx.feature > test_xxx.py

```

When new scenarios' are added the files can be updated with:

```
py.test --generate-missing --feature pool_create.feature test_pool.py

```

# Setup virtual env

Not all packages are available on nix, so one extra step is needed.

```shell
python -m grpc_tools.protoc -i `realpath ../../rpc/proto` --python_out=test/python --grpc_python_out=test/python mayastor.proto
virtualenv --no-setuptools test/python/venv
source test/python/venv/bin/activate
pip install -r test/python/requirements.txt
```

The virtual environment must be activated for every shell. Consider using something as `direnv` to automate this.
The proto files, generated by the tool should never be committed and are already part of gitignore.

# Running the tests

In order to run a test you can run `pytest $test_name`

# Running tests with existing containers

If you need to debug or want the environment not cleaned up you can start the containers
manually. For example:

```
docker-compose up
# different termimal
pytest $test_name --use-running-containers --docker-compose-no-build -s
```
